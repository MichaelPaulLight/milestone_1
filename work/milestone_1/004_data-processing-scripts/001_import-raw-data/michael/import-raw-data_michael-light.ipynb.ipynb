{
  "cells": [
    {
      "cell_type": "code",
      "source": "import pandas as pd\nimport requests\nfrom io import BytesIO\nimport re",
      "metadata": {
        "source_hash": null,
        "execution_start": 1726508659035,
        "execution_millis": 33,
        "deepnote_to_be_reexecuted": false,
        "cell_id": "27864e34dd3947848699db4e61b0ea02",
        "deepnote_cell_type": "code"
      },
      "outputs": [],
      "outputs_reference": null,
      "execution_count": null,
      "block_group": "4453f4fa7dd8476ba099aa6f85cc2c6a",
      "content_dependencies": null
    },
    {
      "cell_type": "code",
      "source": "# Defnining a function to download and combine excel files into a dataframe. \n\n# Takes as input a list of urls, and a number of rows to skip, which varies by year.\n\ndef download_excel_files(urls, rows_to_skip, sheet_number = 1):\n    all_data = []\n\n    for i, url in enumerate(urls, 1):\n        # Download an Excel file\n        response = requests.get(url)\n        \n        if response.status_code == 200:\n            # Read the Excel file into a BytesIO object\n            excel_file = BytesIO(response.content)\n            \n            # Read the second sheet of the Excel file, skip the first 4 rows of metadata\n            df = pd.read_excel(excel_file, skiprows = rows_to_skip, sheet_name = sheet_number)\n            \n            # Add columns to identify which file this data came from\n            df['source_file'] = f\"file_{i}\"\n            df['year'] = url.split('/')[-1].split('_')[0][-2:]  # Extract year from filename\n            \n            all_data.append(df)\n            \n            print(f\"Downloaded and processed file {i}\")\n        else:\n            print(f\"Failed to download file from {url}. Status code: {response.status_code}\")\n\n    if all_data:\n        # Combine all DataFrames into one\n        combined_df = pd.concat(all_data, ignore_index=True)\n        return combined_df\n    else:\n        print(\"No data was successfully downloaded.\")\n        return None",
      "metadata": {
        "source_hash": null,
        "execution_start": 1726506338984,
        "execution_millis": 34,
        "deepnote_to_be_reexecuted": false,
        "cell_id": "5fa57126bc754c8f81ac5c7f988504be",
        "deepnote_cell_type": "code"
      },
      "outputs": [],
      "outputs_reference": null,
      "execution_count": null,
      "block_group": "c0f6f59976584e948956d56b227d0606",
      "content_dependencies": null
    },
    {
      "cell_type": "code",
      "source": "# Attempted to use beautifulsoup to scrape the specialty care clinic file urls, but neither xpath or css selector worked reliably. \n\n# I split the urls into 2 lists, pre_2018_urls and post_2018_urls, on account of inconsistent data structure.\n\n# I also define a data dictionary url to create a dataframe that can be used to standardize column names between the newer and older datasets. \n\n# The plan is to create two dataframes for pre- and post-2018, modify the former's structure to match the latter, and combine.\n\n# Define a list of urls for files pertaining to 2013–2017\n\npre_2018_urls = [\n    \"https://data.chhs.ca.gov/dataset/17bbc0b0-869e-4168-b03b-48fa60c78577/resource/896c699c-07fc-4049-bda0-ff98ac8e3913/download/spcl13utildatafinal.xlsx\",\n    \"https://data.chhs.ca.gov/dataset/17bbc0b0-869e-4168-b03b-48fa60c78577/resource/91fa31b7-8f40-47f1-8bca-bbc063221993/download/spcl14utildatafinal.xlsx\",\n    \"https://data.chhs.ca.gov/dataset/17bbc0b0-869e-4168-b03b-48fa60c78577/resource/171f7631-4cb2-4b20-b238-d5ab3512ae10/download/spcl15utildatafinal.xlsx\",\n    \"https://data.chhs.ca.gov/dataset/17bbc0b0-869e-4168-b03b-48fa60c78577/resource/c6a99713-427a-44df-947d-d46c3402a4d6/download/spcl16_util_data_final-ver2.xlsx\",\n    \"https://data.chhs.ca.gov/dataset/17bbc0b0-869e-4168-b03b-48fa60c78577/resource/e7a2def1-c0dd-41af-a283-46e095bc0af2/download/spcl17_util_data_final.xlsx\"\n]\n\n# Define a list of urls for files pertaining to 2018–2023\n\npost_2018_urls = [\n    \"https://data.chhs.ca.gov/dataset/17bbc0b0-869e-4168-b03b-48fa60c78577/resource/8ad9b464-cbbd-4ad5-b37d-d2daa924768b/download/spcl23_util_data_prelim.xlsx\",\n    \"https://data.chhs.ca.gov/dataset/17bbc0b0-869e-4168-b03b-48fa60c78577/resource/00a9d637-d75a-4ba5-9ed5-87bb01f3a6e3/download/spcl22_util_data_final.xlsx\",\n    \"https://data.chhs.ca.gov/dataset/17bbc0b0-869e-4168-b03b-48fa60c78577/resource/f6339c46-8e35-4466-b972-ce132c43cbf4/download/spcl21_util_data_final.xlsx\",\n    \"https://data.chhs.ca.gov/dataset/17bbc0b0-869e-4168-b03b-48fa60c78577/resource/9c883633-b661-4da3-b39f-50536f60e573/download/spcl20_util_data_final.xlsx\",\n    \"https://data.chhs.ca.gov/dataset/17bbc0b0-869e-4168-b03b-48fa60c78577/resource/188b31e3-2307-479e-9bee-632083f902ba/download/spcl19_util_data_final.xlsx\",\n    \"https://data.chhs.ca.gov/dataset/17bbc0b0-869e-4168-b03b-48fa60c78577/resource/e891cdff-6092-4316-b406-dcbcf4a9c016/download/spcl18_util_data_final.xlsx\"\n]\n\ndata_dictionary_url = [\"https://data.chhs.ca.gov/dataset/17bbc0b0-869e-4168-b03b-48fa60c78577/resource/188b31e3-2307-479e-9bee-632083f902ba/download/spcl19_util_data_final.xlsx\"]",
      "metadata": {
        "source_hash": null,
        "execution_start": 1726506338985,
        "execution_millis": 48,
        "deepnote_to_be_reexecuted": false,
        "cell_id": "13e4ca1eadba4bc6a25aa16bfd433345",
        "deepnote_cell_type": "code"
      },
      "outputs": [],
      "outputs_reference": null,
      "execution_count": null,
      "block_group": "ec7f21c922e344f6b784ac6fb2b92487",
      "content_dependencies": null
    },
    {
      "cell_type": "code",
      "source": "pre_2018_df = download_excel_files(pre_2018_urls, rows_to_skip = [1,2,3])\n\npost_2018_df = download_excel_files(post_2018_urls, rows_to_skip = [1,2,3,4])\n\ndata_dictionary = download_excel_files(data_dictionary_url, rows_to_skip = 0, sheet_number = 3)",
      "metadata": {
        "source_hash": null,
        "execution_start": 1726506339031,
        "execution_millis": 10820,
        "deepnote_to_be_reexecuted": false,
        "cell_id": "a5428c1e93d74f038f9c71cbd69238b1",
        "deepnote_cell_type": "code"
      },
      "outputs": [],
      "outputs_reference": null,
      "execution_count": null,
      "block_group": "516e7cd0ab914422a664dd4c25bab773",
      "content_dependencies": null
    },
    {
      "cell_type": "markdown",
      "source": "# Data cleaning to merge the two sets of historical data",
      "metadata": {
        "formattedRanges": [],
        "cell_id": "6d3dfb745fc6459095a11e6b69b6ac0b",
        "deepnote_cell_type": "text-cell-h1"
      },
      "block_group": "8f73d9dd1cdd4945a246f3353aedb554"
    },
    {
      "cell_type": "code",
      "source": "pre_2018_df",
      "metadata": {
        "source_hash": null,
        "execution_start": 1726506349859,
        "execution_millis": 204,
        "deepnote_table_state": {
          "sortBy": [],
          "filters": [],
          "pageSize": 10,
          "pageIndex": 0,
          "conditionalFilters": []
        },
        "deepnote_table_loading": false,
        "deepnote_to_be_reexecuted": false,
        "cell_id": "ef24854abece47189f83f878493fd9a6",
        "deepnote_cell_type": "code"
      },
      "outputs": [],
      "outputs_reference": null,
      "execution_count": null,
      "block_group": "a32c8923fa9e4fe099ecabc2dc4a6eed",
      "content_dependencies": null
    },
    {
      "cell_type": "code",
      "source": "post_2018_df",
      "metadata": {
        "source_hash": null,
        "execution_start": 1726506350049,
        "execution_millis": 349,
        "deepnote_table_state": {
          "sortBy": [],
          "filters": [],
          "pageSize": 5,
          "pageIndex": 0,
          "conditionalFilters": []
        },
        "deepnote_table_loading": false,
        "deepnote_to_be_reexecuted": false,
        "cell_id": "adbe3af1667b494bbab3208d94029985",
        "deepnote_cell_type": "code"
      },
      "outputs": [],
      "outputs_reference": null,
      "execution_count": null,
      "block_group": "e98bf753323e4495b646dfc1eae1c342",
      "content_dependencies": null
    },
    {
      "cell_type": "code",
      "source": "data_dictionary",
      "metadata": {
        "source_hash": null,
        "execution_start": 1726506350211,
        "execution_millis": 455,
        "deepnote_to_be_reexecuted": false,
        "cell_id": "fc61b66a257d4827b8d8151988fe343a",
        "deepnote_cell_type": "code"
      },
      "outputs": [],
      "outputs_reference": null,
      "execution_count": null,
      "block_group": "2330dccc3c8b46559ac1c2e899a3ec5a",
      "content_dependencies": null
    },
    {
      "cell_type": "code",
      "source": "# Creating a dictionary of old an new column names to rename columns in the pre-2018 dataframe.\n\nold_names = data_dictionary[\"ALIRTS Dataset Header (2017)\"]\n\nnew_names = data_dictionary[\"SIERA Dataset Header (2019)\"]\n\nname_mapping = dict(zip(old_names, new_names))\n\n# Renaming the columns in the pre-2018 dataframe.\n\npre_2018_df = pre_2018_df.rename(columns=name_mapping)",
      "metadata": {
        "source_hash": null,
        "execution_start": 1726506350251,
        "execution_millis": 416,
        "deepnote_to_be_reexecuted": false,
        "cell_id": "ccfab77fef254791bb9a36f0af6440cc",
        "deepnote_cell_type": "code"
      },
      "outputs": [],
      "outputs_reference": null,
      "execution_count": null,
      "block_group": "173fcfbe57de4e57adc256e9ef9e4d78",
      "content_dependencies": null
    },
    {
      "cell_type": "code",
      "source": "pre_2018_df",
      "metadata": {
        "source_hash": null,
        "execution_start": 1726506350252,
        "execution_millis": 415,
        "deepnote_to_be_reexecuted": false,
        "cell_id": "cee758a011a842a08eb59683789a7af9",
        "deepnote_cell_type": "code"
      },
      "outputs": [],
      "outputs_reference": null,
      "execution_count": null,
      "block_group": "d75025abda634df38fa4816994629302",
      "content_dependencies": null
    },
    {
      "cell_type": "code",
      "source": "# Creating a function to combine street address columns in pre-2018 dataframe.\n\ndef combine_street_address(df, col1, col2, new_col_name):\n    \n    # Combine columns, handling NaN values\n    df[new_col_name] = df[col1].fillna('').astype(str) + df[col2].fillna('').apply(lambda x: f', {x}' if x else '')\n    \n    # Remove trailing comma and space if col2 was empty\n    df[new_col_name] = df[new_col_name].str.rstrip(', ')\n\n    # Remove original columns\n    df.drop(columns=[col1, col2], inplace=True)\n\n    return df",
      "metadata": {
        "source_hash": null,
        "execution_start": 1726506778363,
        "execution_millis": 41,
        "deepnote_to_be_reexecuted": false,
        "cell_id": "f25ba0f20a504ab3b68f36041e6a4157",
        "deepnote_cell_type": "code"
      },
      "outputs": [],
      "outputs_reference": null,
      "execution_count": null,
      "block_group": "3ff37bd07d734fbfa933d47e1228068d",
      "content_dependencies": null
    },
    {
      "cell_type": "code",
      "source": "# Creating combined street adress and parent company address columns in the pre-2018 dataframe.\n\ncombine_street_address(pre_2018_df, \"FAC_ADDRESS_ONE\", \"FAC_ADDRESS_TWO\", \"FAC_STR_ADDR\")\n\ncombine_street_address(pre_2018_df, \"PARENT_ADDRESS_ONE\", \"PARENT_ADDRESS_TWO\", \"FAC_PAR_CORP_BUS_ADDR\")",
      "metadata": {
        "source_hash": null,
        "execution_start": 1726506963055,
        "execution_millis": 262,
        "deepnote_to_be_reexecuted": false,
        "cell_id": "10dd65f831d446d38d463f94abe480df",
        "deepnote_cell_type": "code"
      },
      "outputs": [],
      "outputs_reference": null,
      "execution_count": null,
      "block_group": "3590615150854e08b42f203f9c03aa22",
      "content_dependencies": null
    },
    {
      "cell_type": "code",
      "source": "post_2018_df",
      "metadata": {
        "source_hash": null,
        "execution_start": 1726507278143,
        "execution_millis": 259,
        "deepnote_to_be_reexecuted": false,
        "cell_id": "7619f93b6dad4a19bacfb2c2bcd45f44",
        "deepnote_cell_type": "code"
      },
      "outputs": [],
      "outputs_reference": null,
      "execution_count": null,
      "block_group": "1467761f851d4e6da9d1c0036cdcf013",
      "content_dependencies": null
    },
    {
      "cell_type": "code",
      "source": "def compare_columns(df1, df2):\n    set1 = set(df1.columns)\n    set2 = set(df2.columns)\n    \n    only_in_df1 = set1 - set2\n    only_in_df2 = set2 - set1\n    \n    return only_in_df1, only_in_df2\n\n# Usage\ncolumns_only_in_df1, columns_only_in_df2 = compare_columns(pre_2018_df, post_2018_df)\n\nprint(\"Columns only in df1:\", columns_only_in_df1)\nprint(\"Columns only in df2:\", columns_only_in_df2)",
      "metadata": {
        "source_hash": null,
        "execution_start": 1726507102848,
        "execution_millis": 15,
        "deepnote_to_be_reexecuted": false,
        "cell_id": "0d86f1815a644e0b8629defc627ebcc1",
        "deepnote_cell_type": "code"
      },
      "outputs": [],
      "outputs_reference": null,
      "execution_count": null,
      "block_group": "ddbe0046e023412fafe0153756f49221",
      "content_dependencies": null
    },
    {
      "cell_type": "code",
      "source": "pre_2018_df[\"FAC_NO\"].nunique()",
      "metadata": {
        "source_hash": null,
        "execution_start": 1726507324195,
        "execution_millis": 19,
        "deepnote_to_be_reexecuted": false,
        "cell_id": "f341df9a707b48398bb01b5bf9d8f2bd",
        "deepnote_cell_type": "code"
      },
      "outputs": [],
      "outputs_reference": null,
      "execution_count": null,
      "block_group": "22d8fc0caa1b49dda11c6c409e005d43",
      "content_dependencies": null
    },
    {
      "cell_type": "code",
      "source": "post_2018_df[\"FAC_NO\"].nunique()",
      "metadata": {
        "source_hash": null,
        "execution_start": 1726507332875,
        "execution_millis": 46,
        "deepnote_to_be_reexecuted": false,
        "cell_id": "0eeecc3181fd4070995805311f18643c",
        "deepnote_cell_type": "code"
      },
      "outputs": [],
      "outputs_reference": null,
      "execution_count": null,
      "block_group": "1241078a55ee431b9e3604ce3937af74",
      "content_dependencies": null
    },
    {
      "cell_type": "code",
      "source": "def compare_unique_values(df1, df2, column_name):\n    # Get unique values from each DataFrame\n    unique_df1 = set(df1[column_name].unique())\n    unique_df2 = set(df2[column_name].unique())\n    \n    # Find values in df1 but not in df2\n    only_in_df1 = unique_df1 - unique_df2\n    \n    # Find values in df2 but not in df1\n    only_in_df2 = unique_df2 - unique_df1\n    \n    # Find values in both\n    in_both = unique_df1.intersection(unique_df2)\n    \n    return only_in_df1, only_in_df2, in_both\n\n# Usage\ncolumn_to_compare = 'FAC_NO'\nonly_in_df1, only_in_df2, in_both = compare_unique_values(pre_2018_df, post_2018_df, column_to_compare)\n\nprint(f\"Unique values only in df1: {only_in_df1}\")\nprint(f\"Unique values only in df2: {only_in_df2}\")\nprint(f\"Unique values in both: {in_both}\")",
      "metadata": {
        "source_hash": null,
        "execution_start": 1726507432291,
        "execution_millis": 78,
        "deepnote_to_be_reexecuted": false,
        "cell_id": "62899e0e51ea49fcbc980329fb373881",
        "deepnote_cell_type": "code"
      },
      "outputs": [],
      "outputs_reference": null,
      "execution_count": null,
      "block_group": "b11e1c20aff541e983e83f3de1ece376",
      "content_dependencies": null
    },
    {
      "cell_type": "code",
      "source": "import pandas as pd\n\ndef compare_shared_column_types(df1, df2):\n    # Find shared columns\n    shared_columns = list(set(df1.columns) & set(df2.columns))\n    \n    if not shared_columns:\n        print(\"No shared columns found between the DataFrames\")\n        return None\n    \n    # Compare data types\n    comparison = {}\n    for col in shared_columns:\n        type1 = df1[col].dtype\n        type2 = df2[col].dtype\n        comparison[col] = {\n            'df1_type': type1,\n            'df2_type': type2,\n            'match': type1 == type2\n        }\n    \n    # Convert to DataFrame for easy viewing\n    comparison_df = pd.DataFrame.from_dict(comparison, orient='index')\n    \n    return comparison_df\n\n# Usage\ntype_comparison = compare_shared_column_types(pre_2018_df, post_2018_df)\n\nif type_comparison is not None:\n    print(\"Shared column type comparison:\")\n    print(type_comparison)\n    \n    # Identify mismatched columns\n    mismatched = type_comparison[type_comparison['match'] == False]\n    if not mismatched.empty:\n        print(\"\\nColumns with mismatched types:\")\n        print(mismatched)\n    else:\n        print(\"\\nAll shared columns have matching types.\")",
      "metadata": {
        "source_hash": null,
        "execution_start": 1726508366280,
        "execution_millis": 103,
        "deepnote_to_be_reexecuted": false,
        "cell_id": "791a26a738ba4e859cf35ce7cc8f9c18",
        "deepnote_cell_type": "code"
      },
      "outputs": [],
      "outputs_reference": null,
      "execution_count": null,
      "block_group": "b94ab7461b854531b408271da78c7aa5",
      "content_dependencies": null
    },
    {
      "cell_type": "code",
      "source": "# Converting aquisition-related columns in pre-2018 dataframe to types in post-2018 dataframe.\n\n# Pre-2018 dataframe doesn't contain any values for these columns pre-2018, which is why they were imputed differently from those post-2018, which do contain information.\n\npre_2018_df[\"DT_ACQUIRE_01\"] = pd.to_datetime(pre_2018_df[\"DT_ACQUIRE_01\"])\n\npre_2018_df[\"DEEQUIP_01\"] = pre_2018_df[\"DEEQUIP_01\"].astype(\"str\")\n\npre_2018_df[\"MEANS_FOR_ACQUISITION_01\"] = pre_2018_df[\"MEANS_FOR_ACQUISITION_01\"].astype(\"str\")",
      "metadata": {
        "source_hash": null,
        "execution_start": 1726509278543,
        "execution_millis": 254,
        "deepnote_table_state": {
          "sortBy": [],
          "filters": [],
          "pageSize": 10,
          "pageIndex": 0,
          "conditionalFilters": [
            {
              "column": "MEANS_FOR_ACQUISITION_01",
              "operator": "is-not-null",
              "comparativeValues": []
            }
          ]
        },
        "deepnote_table_loading": false,
        "deepnote_to_be_reexecuted": false,
        "cell_id": "0b45828dd9c844bb89e260330c90abba",
        "deepnote_cell_type": "code"
      },
      "outputs": [],
      "outputs_reference": null,
      "execution_count": null,
      "block_group": "4408a874855d4d7ab6fe53d151c6b174",
      "content_dependencies": null
    },
    {
      "cell_type": "code",
      "source": "# Creating a function to remove the string \"District \" from SENATE_DIST, ASSEMBLY_DIST, and CONGRESS_DIST columns in post-2018 dataframe. \n\ndef clean_and_convert_to_numeric(df, columns):\n    def clean_numeric(value):\n        if pd.isna(value):\n            return value\n        # Remove all non-digit characters\n        cleaned = re.sub(r'\\D', '', str(value))\n        return cleaned if cleaned else None\n\n    for col in columns:\n        if col not in df.columns:\n            print(f\"Warning: Column '{col}' not found in the DataFrame. Skipping.\")\n            continue\n        \n        # Apply the cleaning function and convert to integer\n        df[col] = df[col].apply(clean_numeric).astype('Int64')\n    \n    return df\n\ncolumns_to_clean = ['SENATE_DIST', 'CONGRESS_DIST', 'ASSEMBLY_DIST']\npost_2018_df = clean_and_convert_to_numeric(post_2018_df, columns_to_clean)",
      "metadata": {
        "source_hash": null,
        "execution_start": 1726508780347,
        "execution_millis": 141,
        "deepnote_to_be_reexecuted": false,
        "cell_id": "133712a9940349dfac48a8a063457e6c",
        "deepnote_cell_type": "code"
      },
      "outputs": [],
      "outputs_reference": null,
      "execution_count": null,
      "block_group": "ac647d276815454683e11c908dbefd73",
      "content_dependencies": null
    },
    {
      "cell_type": "code",
      "source": "# Creating a function to merge the pre-2018 and post-2018 dataframes\n# Finds all shared columns between df1 and df2 using set intersection.\n# Checks if there are any shared columns. If not, it raises an error.\n# Merges the DataFrames using all shared columns.\n\n# Using how='outer' ensures that all rows from both DataFrames are kept, even if there's no match on all shared columns.\n# suffixes=('_df1', '_df2') are added to disambiguate column names that are in both DataFrames but weren't used for merging.\n\ndef merge_on_shared_columns(df1, df2):\n    # Find shared columns\n    shared_columns = list(set(df1.columns) & set(df2.columns))\n    \n    # Ensure there are shared columns\n    if not shared_columns:\n        raise ValueError(\"No shared columns found between the DataFrames\")\n    \n    # Merge DataFrames on all shared columns\n    merged_df = pd.merge(df1, df2, on=shared_columns, how='outer', suffixes=('_df1', '_df2'))\n    \n    return merged_df",
      "metadata": {
        "source_hash": null,
        "execution_start": 1726508258160,
        "execution_millis": 52,
        "deepnote_to_be_reexecuted": false,
        "cell_id": "e2546f2850824c71bdae003e4a2c8975",
        "deepnote_cell_type": "code"
      },
      "outputs": [],
      "outputs_reference": null,
      "execution_count": null,
      "block_group": "b273ead6e3ef4287a2994a770069fc33",
      "content_dependencies": null
    },
    {
      "cell_type": "code",
      "source": "try:\n    merged_df = merge_on_shared_columns(pre_2018_df, post_2018_df)\n    print(\"Merge successful\")\n    print(f\"Shared columns used for merging: {shared_columns}\")\n    print(f\"Shape of merged DataFrame: {merged_df.shape}\")\nexcept ValueError as e:\n    print(f\"Error: {e}\")\n\n# Checking for duplicate rows:\n\npythonCopyduplicate_rows = merged_df[merged_df.duplicated()]\n\nif not duplicate_rows.empty:\n    print(f\"Number of duplicate rows: {len(duplicate_rows)}\")\n\n# For null values created by the merge:\n\npythonCopynull_counts = merged_df.isnull().sum()\nprint(\"Null value counts per column:\")\nprint(null_counts[null_counts > 0])\n\n# Verify the merge result:\n\npythonCopyprint(f\"Rows in df1: {len(df1)}\")\nprint(f\"Rows in df2: {len(df2)}\")\nprint(f\"Rows in merged_df: {len(merged_df)}\")\nprint(f\"Columns in merged_df: {len(merged_df.columns)}\")",
      "metadata": {
        "source_hash": null,
        "execution_start": 1726508261067,
        "execution_millis": 340,
        "deepnote_to_be_reexecuted": false,
        "cell_id": "ac0879287b8647d4a3fbda0be552ad04",
        "deepnote_cell_type": "code"
      },
      "outputs": [],
      "outputs_reference": null,
      "execution_count": null,
      "block_group": "6e41f92be7914c83a7dd236009d5cb35",
      "content_dependencies": null
    },
    {
      "cell_type": "code",
      "source": "print(merged_df[\"FAC_NO\"].nunique())\nprint(post_2018_df[\"year\"].nunique())",
      "metadata": {
        "source_hash": null,
        "execution_start": 1726507898091,
        "execution_millis": 74,
        "deepnote_to_be_reexecuted": false,
        "cell_id": "726837b6abd94fabbfbcc7562da03906",
        "deepnote_cell_type": "code"
      },
      "outputs": [],
      "outputs_reference": null,
      "execution_count": null,
      "block_group": "fd5c41aab69c416089eb6b7d82b30ecd",
      "content_dependencies": null
    },
    {
      "cell_type": "code",
      "source": "merged_df\n",
      "metadata": {
        "source_hash": null,
        "execution_start": 1726507915365,
        "execution_millis": 156,
        "deepnote_to_be_reexecuted": false,
        "cell_id": "1fa8bbbbcde346ad81084320e5eba3ac",
        "deepnote_cell_type": "code"
      },
      "outputs": [],
      "outputs_reference": null,
      "execution_count": null,
      "block_group": "42e8de5fb1244e999c4cade7ac0fae47",
      "content_dependencies": null
    },
    {
      "cell_type": "code",
      "source": "",
      "metadata": {
        "cell_id": "6ffa46196852468191af684b078c6b45",
        "deepnote_cell_type": "code"
      },
      "outputs": [],
      "outputs_reference": null,
      "execution_count": null,
      "block_group": "f3919a7a118943acbbcb05d1951a500e",
      "content_dependencies": null
    },
    {
      "cell_type": "markdown",
      "source": "<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=9a5367f9-570e-4fa7-91cf-2de38c70a230' target=\"_blank\">\n<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\nCreated in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>",
      "metadata": {
        "created_in_deepnote_cell": true,
        "deepnote_cell_type": "markdown"
      }
    }
  ],
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "deepnote_notebook_id": "32da149562af4ca6b675835936c28be0",
    "deepnote_execution_queue": []
  }
}